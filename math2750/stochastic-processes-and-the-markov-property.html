<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1 Stochastic processes and the Markov property | MATH2750 Introduction to Markov Processes</title>
  <meta name="description" content="1 Stochastic processes and the Markov property | MATH2750 Introduction to Markov Processes" />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="1 Stochastic processes and the Markov property | MATH2750 Introduction to Markov Processes" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1 Stochastic processes and the Markov property | MATH2750 Introduction to Markov Processes" />
  
  
  

<meta name="author" content="Matthew Aldridge" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="random-walk.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><b>MATH2750 notes</b></a></li>

<li class="divider"></li>
<li class="part"><span><b>Introduction</b></span></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About the module</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#organisation-of-the-module"><i class="fa fa-check"></i>Organisation of the module</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#lectures"><i class="fa fa-check"></i>Lectures</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#problem-sheets"><i class="fa fa-check"></i>Problem sheets</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#workshops"><i class="fa fa-check"></i>Workshops</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#assessments"><i class="fa fa-check"></i>Assessments</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#computer-practicals"><i class="fa fa-check"></i>Computer practicals</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#exam"><i class="fa fa-check"></i>Exam</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#office-hours"><i class="fa fa-check"></i>Office hours</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#content-of-the-module"><i class="fa fa-check"></i>Content of the module</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#books"><i class="fa fa-check"></i>Books</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="stochastic-processes-and-the-markov-property.html"><a href="stochastic-processes-and-the-markov-property.html"><i class="fa fa-check"></i><b>1</b> Stochastic processes and the Markov property</a><ul>
<li class="chapter" data-level="1.1" data-path="stochastic-processes-and-the-markov-property.html"><a href="stochastic-processes-and-the-markov-property.html#deterministic-and-random-models"><i class="fa fa-check"></i><b>1.1</b> Deterministic and random models</a></li>
<li class="chapter" data-level="1.2" data-path="stochastic-processes-and-the-markov-property.html"><a href="stochastic-processes-and-the-markov-property.html#stochastic-processes"><i class="fa fa-check"></i><b>1.2</b> Stochastic processes</a></li>
<li class="chapter" data-level="1.3" data-path="stochastic-processes-and-the-markov-property.html"><a href="stochastic-processes-and-the-markov-property.html#markov-property"><i class="fa fa-check"></i><b>1.3</b> Markov property</a></li>
</ul></li>
<li class="part"><span><b>Part I: Discrete time Markov chains</b></span></li>
<li class="chapter" data-level="2" data-path="random-walk.html"><a href="random-walk.html"><i class="fa fa-check"></i><b>2</b> Random walk</a><ul>
<li class="chapter" data-level="2.1" data-path="random-walk.html"><a href="random-walk.html#simple-random-walk"><i class="fa fa-check"></i><b>2.1</b> Simple random walk</a></li>
<li class="chapter" data-level="2.2" data-path="random-walk.html"><a href="random-walk.html#general-random-walks"><i class="fa fa-check"></i><b>2.2</b> General random walks</a></li>
<li class="chapter" data-level="2.3" data-path="random-walk.html"><a href="random-walk.html#exact-distribution-of-the-simple-random-walk"><i class="fa fa-check"></i><b>2.3</b> Exact distribution of the simple random walk</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="gamblers-ruin.html"><a href="gamblers-ruin.html"><i class="fa fa-check"></i><b>3</b> Gambler’s ruin</a><ul>
<li class="chapter" data-level="3.1" data-path="gamblers-ruin.html"><a href="gamblers-ruin.html#gamblers-ruin-markov-chain"><i class="fa fa-check"></i><b>3.1</b> Gambler’s ruin Markov chain</a></li>
<li class="chapter" data-level="3.2" data-path="gamblers-ruin.html"><a href="gamblers-ruin.html#probability-of-ruin"><i class="fa fa-check"></i><b>3.2</b> Probability of ruin</a></li>
<li class="chapter" data-level="3.3" data-path="gamblers-ruin.html"><a href="gamblers-ruin.html#expected-duration-of-the-game"><i class="fa fa-check"></i><b>3.3</b> Expected duration of the game</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linear-difference-equations.html"><a href="linear-difference-equations.html"><i class="fa fa-check"></i><b>4</b> Linear difference equations</a><ul>
<li class="chapter" data-level="4.1" data-path="linear-difference-equations.html"><a href="linear-difference-equations.html#homogeneous-linear-difference-equations"><i class="fa fa-check"></i><b>4.1</b> Homogeneous linear difference equations</a></li>
<li class="chapter" data-level="4.2" data-path="linear-difference-equations.html"><a href="linear-difference-equations.html#probability-of-ruin-for-the-gamblers-ruin"><i class="fa fa-check"></i><b>4.2</b> Probability of ruin for the gambler’s ruin</a></li>
<li class="chapter" data-level="4.3" data-path="linear-difference-equations.html"><a href="linear-difference-equations.html#inhomogeneous-linear-difference-equations"><i class="fa fa-check"></i><b>4.3</b> Inhomogeneous linear difference equations</a></li>
<li class="chapter" data-level="4.4" data-path="linear-difference-equations.html"><a href="linear-difference-equations.html#expected-duration-for-the-gamblers-ruin"><i class="fa fa-check"></i><b>4.4</b> Expected duration for the gambler’s ruin</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="how-to-solve-linear-difference-equations.html"><a href="how-to-solve-linear-difference-equations.html"><i class="fa fa-check"></i>How to solve linear difference equations</a><ul>
<li class="chapter" data-level="" data-path="how-to-solve-linear-difference-equations.html"><a href="how-to-solve-linear-difference-equations.html#how-to-solve-homogeneous-linear-difference-equations"><i class="fa fa-check"></i>How to solve homogeneous linear difference equations</a></li>
<li class="chapter" data-level="" data-path="how-to-solve-linear-difference-equations.html"><a href="how-to-solve-linear-difference-equations.html#how-to-solve-inhomogeneous-linear-difference-equations"><i class="fa fa-check"></i>How to solve inhomogeneous linear difference equations</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html"><i class="fa fa-check"></i><b>5</b> Discrete time Markov chains</a></li>
<li class="chapter" data-level="6" data-path="examples-from-actuarial-science.html"><a href="examples-from-actuarial-science.html"><i class="fa fa-check"></i><b>6</b> Examples from actuarial science</a></li>
<li class="chapter" data-level="7" data-path="class-structure.html"><a href="class-structure.html"><i class="fa fa-check"></i><b>7</b> Class structure</a></li>
<li class="chapter" data-level="8" data-path="hitting-times.html"><a href="hitting-times.html"><i class="fa fa-check"></i><b>8</b> Hitting times</a></li>
<li class="chapter" data-level="9" data-path="recurrence-and-transience.html"><a href="recurrence-and-transience.html"><i class="fa fa-check"></i><b>9</b> Recurrence and transience</a></li>
<li class="chapter" data-level="10" data-path="stationary-distributions.html"><a href="stationary-distributions.html"><i class="fa fa-check"></i><b>10</b> Stationary distributions</a></li>
<li class="chapter" data-level="" data-path="how-to-find-stationary-distributions.html"><a href="how-to-find-stationary-distributions.html"><i class="fa fa-check"></i>How to find stationary distributions</a></li>
<li class="chapter" data-level="11" data-path="long-term-behaviour-of-markov-chains.html"><a href="long-term-behaviour-of-markov-chains.html"><i class="fa fa-check"></i><b>11</b> Long-term behaviour of Markov chains</a></li>
<li class="chapter" data-level="" data-path="summary-of-part-i.html"><a href="summary-of-part-i.html"><i class="fa fa-check"></i>Summary of Part I</a></li>
<li class="part"><span><b>Part II: Continuous time Markov jump processes</b></span></li>
<li class="chapter" data-level="12" data-path="poisson-process-and-the-poisson-distribution.html"><a href="poisson-process-and-the-poisson-distribution.html"><i class="fa fa-check"></i><b>12</b> Poisson process and the Poisson distribution</a></li>
<li class="chapter" data-level="13" data-path="poisson-process-and-the-exponential-distribution.html"><a href="poisson-process-and-the-exponential-distribution.html"><i class="fa fa-check"></i><b>13</b> Poisson process and the exponential distribution</a></li>
<li class="chapter" data-level="14" data-path="poisson-process-in-infinitesimal-time-periods.html"><a href="poisson-process-in-infinitesimal-time-periods.html"><i class="fa fa-check"></i><b>14</b> Poisson process in infinitesimal time periods</a></li>
<li class="chapter" data-level="15" data-path="counting-processes.html"><a href="counting-processes.html"><i class="fa fa-check"></i><b>15</b> Counting processes</a></li>
<li class="chapter" data-level="16" data-path="continuous-time-markov-jump-processes-jump-chain-and-holding-times.html"><a href="continuous-time-markov-jump-processes-jump-chain-and-holding-times.html"><i class="fa fa-check"></i><b>16</b> Continuous time Markov jump processes: jump chain and holding times</a></li>
<li class="chapter" data-level="17" data-path="forward-and-backward-equations.html"><a href="forward-and-backward-equations.html"><i class="fa fa-check"></i><b>17</b> Forward and backward equations</a></li>
<li class="chapter" data-level="18" data-path="class-structure-and-hitting-times.html"><a href="class-structure-and-hitting-times.html"><i class="fa fa-check"></i><b>18</b> Class structure and hitting times</a></li>
<li class="chapter" data-level="19" data-path="long-term-behaviour-of-markov-jump-processes.html"><a href="long-term-behaviour-of-markov-jump-processes.html"><i class="fa fa-check"></i><b>19</b> Long-term behaviour of Markov jump processes</a></li>
<li class="chapter" data-level="20" data-path="queues.html"><a href="queues.html"><i class="fa fa-check"></i><b>20</b> Queues</a></li>
<li class="chapter" data-level="" data-path="summary-of-part-ii.html"><a href="summary-of-part-ii.html"><i class="fa fa-check"></i>Summary of Part II</a></li>
<li class="part"><span><b>Revision</b></span></li>
<li class="chapter" data-level="21" data-path="frequently-asked-questions.html"><a href="frequently-asked-questions.html"><i class="fa fa-check"></i><b>21</b> Frequently asked questions</a></li>
<li class="chapter" data-level="22" data-path="exam-preparation.html"><a href="exam-preparation.html"><i class="fa fa-check"></i><b>22</b> Exam preparation</a></li>
<li class="divider"></li>
<li><a href="https://mpaldridge.github.io/">Matthew Aldridge</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH2750 Introduction to Markov Processes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="stochastic-processes-and-the-markov-property" class="section level1">
<h1><span class="header-section-number">1</span> Stochastic processes and the Markov property</h1>
<div class="summ">
<ul>
<li>
Stochastic processes with discrete/continuous state space and discrete/continuous time
</li>
<li>
The Markov ‘memoryless’ property
</li>
</ul>
</div>
<div id="deterministic-and-random-models" class="section level2">
<h2><span class="header-section-number">1.1</span> Deterministic and random models</h2>
<p>A <em>model</em> is an imitation of a real-world system. For example, you might want to have a model to imitate the world’s population, the level of water in a reservoir, future cashflows of a pension scheme, or future stock prices. Models allow us to try to predict what might happen in the real world in a low risk, cost effective and fast way.</p>
<p>To design a model requires a set of assumptions about how it will work and suitable parameters need to be determined, perhaps based on past collected data.</p>
<p>An important distinction is between <em>deterministic</em> models and <em>random</em>} (or <em>stochastic</em>) models. Deterministic models do not contain any random components, so the output is completely determined by the inputs and any parameters. Random models have variable outcomes, so can be run many times to give a sense of the range of possible outcomes.</p>
<p>Consider models for:</p>
<ol style="list-style-type: decimal">
<li>the future position of the Moon as it orbits the Earth,</li>
<li>the future price of shares in Apple.</li>
</ol>
<p>In (a), the random components – for example, the effect of meteorites striking the Moon’s surface – are not very significant and a deterministic model based on physical laws is good enough for most purposes. In (b), the share price from day to day is highly uncertain, so a random model can take into account the variability and unpredictability in a useful way.</p>
<p>In this module we will see many examples of stochastic models. Lots of the applications we will consider come from financial mathematics and actuarial science where the use of models that take into account uncertainty is very important, but the principles apply in many areas.</p>
</div>
<div id="stochastic-processes" class="section level2">
<h2><span class="header-section-number">1.2</span> Stochastic processes</h2>
<p>If we want to model, for example, the total number of claims to an insurance company in the whole of 2019, we can use a random variable <span class="math inline">\(X\)</span> to model this – perhaps a Poisson distribution with an appropriate mean, for example. However, if we want to track how the number of claims changes over the course of the year 2019, we will need to use a <em>stochastic process</em>. (The word ‘stochastic’ means the same thing as ‘random’.)</p>
<p>A stochastic process, which we will write as <span class="math inline">\((X_n)\)</span>, is an indexed sequence of random variables that are (usually) dependent on each other. Each random variable <span class="math inline">\(X_n\)</span> takes a value in a <em>state space</em> <span class="math inline">\(\mathcal S\)</span> which is the set of possible values for the process. As with usual random variables, the state space <span class="math inline">\(\mathcal S\)</span> can be <em>discrete</em> or <em>continuous</em>. A discrete state space denotes a set of distinct possible outcomes, which can be finite or countably infinite. For example, <span class="math inline">\(\mathcal S = \{\text{Heads},\text{Tails}\}\)</span> is the state space for a single coin flip, while in the case of counting insurance claims, the state space would be the nonnegative integers <span class="math inline">\(\mathcal S = \mathbb Z_+ = \{0,1,2,\dots\}\)</span>. A continuous state spaces denotes an uncountably infinite continuum of gradually varying outcomes. For example, the nonnegative real line <span class="math inline">\(\mathcal S = \mathbb R_+ = \{x \in \mathbb R : x \geq 0\}\)</span> is the state space for the amount of rainfall on a given day, while a bounded subset of <span class="math inline">\(\mathbb R^3\)</span> is the state space for the position of a gas particle in a box.</p>
<p>Further, the process has an <em>index set</em> that puts the random variables that make up the process in order. The index set is usually interpreted as a time variable, telling us when the process will be measured. The index set for time can also be discrete or continuous. Discrete time denotes a process sampled at different points, often denoted by <span class="math inline">\(n = 0,1,2,\dots\)</span>, while continuous time denotes a process monitored constantly over time, often denoted by <span class="math inline">\(t \in \mathbb R_+ = \{x \in \mathbb R : x \geq 0\}\)</span>. In the insurance example, we might count up the number of claims each day – then the discrete index set will be the days of the year, which we could denote <span class="math inline">\(\{1,2,\dots,365\}\)</span>. Alternatively, we might want to keep a constant tally that we update after every claim, requiring a continuous time index representing time across the whole year. In discrete time, we can write down the first few steps of the process as <span class="math inline">\((X_0, X_1, X_2, \dots)\)</span>.</p>
<p>This gives us four possibilities in total:</p>
<ul>
<li>Discrete time, discrete space
<ul>
<li>Example: Number of students turning up to each lecture of .</li>
<li><em>Markov chains</em> – discrete time, discrete space stochastic processes with a certain ‘Markov property’ – are the main topic of the first half of this module.</li>
</ul></li>
<li>Discrete time, continuous space
<ul>
<li>Example: Daily maximum temperature in Leeds.</li>
<li>We will briefly mention continuous space Markov chains in the first half of the course.</li>
</ul></li>
<li>Continuous time, discrete space
<ul>
<li>Example: Number of visitors to a webpage over time.</li>
<li><em>Markov jump processes</em> – continuous time, discrete space stochastic processes with the ‘Markov property’ – are the main topic of the second half of this module.</li>
</ul></li>
<li>Continuous time, continuous space
<ul>
<li>Example: Level of the FTSE 100 share index over time.</li>
<li>Such processes, especially the famous Brownian motion – another process with the Markov property – are very important, but outside the scope of this course. See <code>MATH3733</code> Stochastic Financial Modelling next year, for example.</li>
</ul></li>
</ul>
</div>
<div id="markov-property" class="section level2">
<h2><span class="header-section-number">1.3</span> Markov property</h2>
<p>Because stochastic processes consist of a large number – even infinitely many – random variables that could all be dependent on each other, they can get extremely complicated. The Markov property is a crucial property that restricts the type of dependences in a process, to make the process easier to study, yet still leaves most of the useful and interesting examples intact.</p>
<p>Think of a simple board game where we roll a die and move that many squares forward on the board. Suppose we are currently on the square <span class="math inline">\(X_n\)</span>. Then which square <span class="math inline">\(X_{n+1}\)</span> we move to on our next turn:</p>
<ul>
<li>is random, since it depends on the roll of the die;</li>
<li>depends on where we are now <span class="math inline">\(X_n\)</span>, since the score of die will be added onto the number our current square;</li>
<li>given the square we are now <span class="math inline">\(X_n\)</span>, it doesn’t depend any further on which sequence of squares <span class="math inline">\(X_0, X_1, \dots, X_{n-1}\)</span> we used to get here.</li>
</ul>
<p>It is this third point that is the crucial property of the stochastic processes we will study in this course, and it is called the <em>Markov property</em> or <em>memoryless property</em>. We say ‘memoryless’, because it’s as if the process forgot how it got here – the process before this moment has no bearing on the future given where we are now. A mathematical way to say this is that ‘the past and the future are conditionally independent given the present.’</p>
<p>To write this down formally, we need to recall <em>conditional probability</em>: the conditional probability of an event <span class="math inline">\(A\)</span> given another event <span class="math inline">\(B\)</span> is written <span class="math inline">\(\mathbb P(A \mid B)\)</span>, and is the probability that <span class="math inline">\(A\)</span> occurs <em>given</em> that <span class="math inline">\(B\)</span> definitely occurs. You may remember the definition <span class="math display">\[ \mathbb P(A \mid B) = \frac{\mathbb P(A \cap B)}{\mathbb P(B)} , \]</span> although is often more useful to reason directly about conditional probabilities than use this formula.</p>

<div class="definition">
<span id="def:unnamed-chunk-2" class="definition"><strong>Definition 1.1  </strong></span> Let <span class="math inline">\((X_n) = (X_0, X_1, X_2, \dots)\)</span> be a stochastic process in  time <span class="math inline">\(n = 0,1,2,\dots\)</span>. Then we say that <span class="math inline">\((X_n)\)</span> has the <em>Markov property</em> or is <em>Markovian</em> if, for all times <span class="math inline">\(n\)</span> and all states <span class="math inline">\(x_0, x_1, \dots,x_n, x_{n+1} \in \mathcal S\)</span> we have <span class="math display">\[  \mathbb P(X_{n+1}=x_{n+1} \mid X_{n}=x_{n}, \dots,X_1 = x_1, X_0=x_0)=\mathbb P(X_{n+1}=x_{n+1} \mid X_{n}=x_{n}) . \]</span>
</div>

<p>Here, the left hand side is the probability we go to state <span class="math inline">\(x_{n+1}\)</span> next conditioned on the entire history of the process, while the right hand side is the probability we go to state <span class="math inline">\(x_{n+1}\)</span> next conditioned only on where we are now. So this property tells us that it only matters where we are now and not how we got here.</p>
<p>(There’s also a similar definition for continuous time processes, which we’ll come to later in the course.)</p>
<p>Stochastic processes that have the Markov property are much easier to study than general processes, as we only have to keep track of where we are now and we don’t have to keep track of the entire history that came before.</p>
</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="random-walk.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
