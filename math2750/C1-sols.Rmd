---
title: "Computational Practical 1 -- Example Report"
author: "Matthew Aldridge"
date: "*MATH2750 Introduction to Markov Processes*"
output: html_document
---
  


*We will be studying the simple random walk starting from $X_0 = 0$ with up probability $p = 0.6$ and down probability $q = 1 - p = 0.4$.*

**Question 1.** *Produce a sample of the first $N = 10$ steps of this simple random walk.*


The function `Z <- rbinom(N, n, p)` produces a vector $\mathbf{Z}$ of $N$ independent Binomial$(n,p)$ random variables. Setting $n = 1$, we get $N$ Bernoulli trials, which we can use to form our increments process. To get the increments to be $-1$ and $1$ rather than $0$ and $1$, we can take instead $2\mathbf{Z} - 1$, since $2\times 1 - 1 = 1$ and $2 \times 0 - 1 = -1$. We could alternatively have used `Z[Z == 0] = -1`, which rewrites all the values of $\mathbf{Z}$ that equal $0$ to now be $-1$. Thus the code
```{r}
p <- 0.6
N <- 10
Z <- rbinom(N, 1, p)
Z <- 2*Z - 1
```
produces the increments process. We then use the cumulative sum command `cumsum` to form the random walk $\mathbf{X}$ from the increments.
```{r}
X <- cumsum(Z)
X
```

If needed, we can add the starting point $X_0 = 0$ with
```{r}
c(0,X)
```



**Question 2.** *Plot a sample of the random walk for $N = 10$ steps and for $N = 10000$ steps. Try to make your plot look smart, for example by giving it a title and labelling the axes. Briefly comment on the plots.*


For $N = 10$, we plot the random walk with
```{r}
plot(0:N, c(0,X),
     type="b", col="blue",
     xlab="time step, n",
     ylim=c(-N,N), ylab=bquote("Random walk, " ~ X[n]),  # This gives X_n with a subscript
     main="Simple random walk, 10 steps")
```

Here, `type="b"` means we plot **both** points and lines. By plotting `c(0,X)` against `0:N` ${}= (0,1,\dots, N)$, we ensure our plot also includes the starting point $X_0 = 0$ of the random walk.

We see that the random walk takes steps up $1$ and down $1$ roughly equally, although slightly more likely to be up on average. There is (usually) quite a lot of variation, in that the walk often goes up then down rather than a regular drift upwards.

We can repeat this for $N = 10000$, to get
```{r}
N <- 10000
Z <- rbinom(N, 1, p)
Z <- 2*Z - 1
X <- cumsum(Z)
plot(0:N, c(0,X),
     type="l", col="blue",
     xlab="time step, n", 
     ylab=bquote("Random walk, " ~ X[n]),
     main="Simple random walk, 10000 steps")
```

Here, `type="l"` just gives **lines**, which is easier to read when there are many datapoints. 

We see that the main drift of the random walk is steadily upwards, although there are some small variations within the linear drift. This is because the standard deviation is $\sqrt{4pqn}$, which scales like $\sqrt{n}$, while the drift is $(p-q)n$, which scales like $n$. So as the number of steps gets larger, the drift becomes much more important than the variation, and the curve looks increasinly smooth.



**Question 3.** *Make a function in R that produces a sample of a simple random walk for given $p$ of length $N$. Test your function to check it works. What are the advantages of making a a function like this?*


Our function is
```{r}
RandomWalk <- function(N, p)
  {
    Z <- rbinom(N, 1, p)
    Z <- 2*Z - 1
    cumsum(Z)
  }
```

We can also make a function to plot the random walk.
```{r}
PlotRandomWalk <- function(X)
  {
    plot(0:length(X), c(0,X),
         type="l", col="blue",
         xlab="time step, n", 
         ylab=bquote("Random walk, " ~ X[n]),
         main="Simple random walk")
  }
```

This has the advantage that we can now very quickly produce and plot random walks without writing (or copy-pasting) many lines of code.

We can test it works by producing a simple random walk of length $50$ with $p = 0.3$
```{r}
X <- RandomWalk(50,0.3)
PlotRandomWalk(X)
```



**Question 4.** *Estimate the expected value of of the simple random walk at $N = 100$ steps by simulating many random walks and taking an average. How does this compare with the true answer?*


We know that the true expectation is
\[ \mathbb{E}X_{100} = 100(p-q) = 100(0.6 - 0.4) = 20 . \]
  
We use the `replicate` function to get $10000$ samples of the random walk, and print the mean value of $X_{100}$,
```{r}
N <- 100
trials <- 10000
samples <- replicate(trials, RandomWalk(N,p)[N])
mean(samples)
```
This simulated value of $`r mean(samples)`$ is very close to the true value of $20$.



**Question 5.** (Optional) *Investigate estimating other properties of the simple random walk through simulation.*


Let's try investigating the ruin probability of a gambler's ruin problem.
```{r}
GamblersRuin <- function(p,a,m)
  {
    Money <- a  # Alice starts with Â£a
    
    while(Money > 0 && Money < m)  # until the game finishes...
      {
        Money <- Money + (2*rbinom(1,1,p) - 1)  # ...play another round
      }
    
    ifelse(Money == 0, 1, 0) # outputs 1 if Alice ruins; outputs 0 if Bob ruins
  }


p <- 0.4
a <- 2
m <- 5

trials <- 10000
GRsamples <- replicate(trials, GamblersRuin(p,a,m))
mean(GRsamples)  # estimated ruin probability
```

We can compare this simulated answer $`r mean(GRsamples)`$ to the true ruin probability given by
$$ r_a = \frac{\rho^a - \rho^m}{1 - \rho^m} ,$$
where $\rho = q/p$. We calculate this in R.
```{r}
TrueRuinProb <- function(p,a,m)
  {
    rho <- (1-p)/p
    (rho^a - rho^m)/(1 - rho^m)
}

TrueRuinProb(p,a,m)
```

This formula gives the answer $r_a = `r TrueRuinProb(p,a,m)`$, which is close to the simulated answer $`r mean(GRsamples)`$.
