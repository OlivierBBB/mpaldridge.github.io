---
title:  "Computational Practical 2 & Assessment 2: Example report"
author: "[Matthew Aldridge](mailto:m.aldridge@leeds.ac.uk)"
date:   "MATH2750 Introduction to Markov Processes (2019--20)"
output: html_document
---


  
*The following is an example report answering the questions on the Computational Practical 2 problem sheet, which double as Assessment 2. You can view the original problem sheet [in HTML format](https://mpaldridge.github.io/math2750/C2.html) or [as an Rmd file](https://mpaldridge.github.io/math2750/C2.Rmd).*



***



I started by reading in the three functions, `TransMat`, `MarkovChain` and `StatDist`.

<!-- echo = FALSE means that the code is executed but does not appear in the report. -->
```{r, echo = FALSE}
# Produces a transition matrix for a Markov chain based on a parameter eps
TransMat <- function(eps) {
  matrix(c(0.1, 0.9,   0,       0,       0,   0,
           0.4, 0.2, 0.4,       0,       0,   0,
             0, 0.5,   0,     0.5,       0,   0,
             0,   0, 0.5, 0.5-eps,     eps,   0,
             0,   0,   0,     eps, 0.3-eps, 0.7,
             0,   0,   0,       0,     0.5, 0.5),
         nrow = 6, ncol = 6, byrow = TRUE)
}


# Simulates a Markov chain with transition matrix P for N steps from X0
MarkovChain <- function(N, X0, P) {
  X <- numeric(N)   # empty vector of length N
  space <- nrow(P)  # number of points in sample space
  
  now <- X0
  for (n in 1:N) {
    now <- sample(space, 1, prob = P[now, ])
    X[n] <- now
  }
  
  X
}


# Solves pi %*% P = pi, for the stationary distribution of a Markov chain
StatDist <- function(P) {
  LeftEigen <- eigen(t(P))
  statmeas <- LeftEigen$vectors[, 1]  # Unnormalised stationary measure
  statmeas / sum(statmeas)            # Normalised stationary distribution
}
```



**Question 1.** *Using the function `TransMat`, produce the transition matrix for $\epsilon = 0.2$. Using the function `MarkovChain`, simulate $N = 50$ steps of this Markov chain starting from $X_0 = 1$. Check it has worked, perhaps by plotting a graph or examining the vector produced. Comment on what you find.*


The desired transition matrix is the following:

```{r}
eps <- 0.2
P   <- TransMat(eps)
P
```

We produce the Markov chain as follows.

```{r}
N  <- 50
X0 <- 1
X  <- MarkovChain(N, X0, P)
X
```

We can also plot the Markov chain, including the point $X_0 = 1$.

```{r}
plot(0:N, c(X0, X),
     main = bquote("Markov Chain with" ~ epsilon == .(eps)),
     xlab = "time, n",
     ylab = bquote("state," ~ X[n]),
     ylim = c(1, 6),
     type = "b",
     col  = "blue")
```

At each step, the Markov chain moves either up one, down one, or stays the same, as the transition matrix says it should. Due to random numbers, the realisation changes each time we run the code. However, we see that it quite often stays among states $\{1,2,3,4\}$ or states $\{5,6\}$ for quite a long time before moving to the other set. This is because $p_{45} = p_{54} = \epsilon = `r eps`$, so crossing the barrier between states 4 and 5 is somewhat rare.


**Question 2.** *Calculate the proportion of time spent in each state. What if you choose $N$ to be very large? How does this compare with the stationary distribution? Relate what you have found to a result in the course.*


We use the `table` function to see the proportion of time in each state. To save time later, we make a function to do this.

```{r}
TimeSpent <- function(X, states) {
  num_visits <- table(factor(X, 1:states))
  num_visits / length(X)
}

proportion_time <- TimeSpent(X, 6)
proportion_time
```

The ergodic theorem says that for a irreducible positive recurrent Markov chain, like this one, the long-term proportion of time spent in each state tends to the stationary distribution. Note that this is a *long-term* result as $N \to \infty$, so we should not expect the current value of $N = `r N`$ to work. Instead, let's try a much larger value of $N$.

```{r}
N <- 100000
X <- MarkovChain(N, X0, P)
proportion_time <- TimeSpent(X, 6)
```

We can compare this with the stationary distribution produced by `StatDist`.
```{r}
stationary <- StatDist(P)
round(rbind(proportion_time, stationary), 4)

barplot(rbind(proportion_time, stationary),
        beside = TRUE,
        xlab = "State",
        legend.text = c("Proportion of time", "Stationary distribution"),
        args.legend = list(x = "top"))  # legend in the centre
```

We see that the proportion of time spent in each state for $N = `r N`$ is very close to the stationary distribution, as the ergodic theorem predicts.



**Question 3.** *For each state, estimate the expected return time $\mu_i$. What do you expect the answer to be? How does your result compare with this?*

We estimate the expected return time by looking at the mean return time of our simulation. Again, writing a function saves us time in the long run.

```{r}
MeanReturn <- function(vect, value) {
  visits <- which(vect == value)
  return_times <- diff(visits)
  mean(return_times)
}

# The sapply function here calculates all the MeanReturns at once
# without having to write it out six times or use a "for" loop
mean_return_times <- sapply(1:6, MeanReturn, vect = X)
```

In the function `MeanReturn`, `visits` is a vector of time steps at which the Markov chain visited a given state $i$, `return_times` is a vector of the number of time steps in between those visits, and `mean(return_times)` is the mean of those return times.

A result from the course tells us that the expected return times should be equal to the reciprical of the stationary distribution; that is, $\mu_i = 1/\pi_i$, where $\boldsymbol\pi = (\pi_i)$ is the stationary distribution.

```{r}
rec_stat <- 1 / stationary
round(rbind(mean_return_times, rec_stat), 2)
barplot(rbind(mean_return_times, rec_stat),
        beside = TRUE,
        legend.text = c("Simulated return times", "Expected return times"),
        xlab = "State",
        names.arg = 1:6)
```

We see that these are indeed very close, as predicted by theory.



**Question 4.** *What do you think would happen if you were to repeat the above exercises with $\epsilon = 0.01$? What about $\epsilon = 10^{-6}$? What about $\epsilon = 0$? Explain your answers.*


As we noted in our answer to Question 1, there is a natural "barrier" between the sets $\{1,2,3,4\}$ and $\{5,6\}$, since $p_{45} = p_{54} = \epsilon$. When $\epsilon$ is very small (but nonzero), we can expect crossing that barrier to be very rare -- only about every $1/\epsilon$ visits to states $4$ or $5$, where $1/\epsilon = 100$ or $1\,000\,000$ here.

<!-- Add eval = FALSE if the Tikz picture doesn't compile properly -->
```{r, engine = "tikz", fig.ext = "svg", echo = FALSE, eval = FALSE}
\usetikzlibrary{automata}

\begin{tikzpicture}[auto]
  \node[state] (1) at (0,0) {1};
  \node[state] (2) at (2,0) {2};
  \node[state] (3) at (4,0) {3};
  \node[state] (4) at (6,0) {4};
  \node[state] (5) at (9,0) {5};	
  \node[state] (6) at (11,0) {6};
	
  \path[->] (1) edge[loop left] node {0.1} ();
  \path[->] (2) edge[loop above] node {0.2} ();
  \path[->] (4) edge[loop above] node {$0.5 - \epsilon$} ();
  \path[->] (5) edge[loop above] node {$0.3 - \epsilon$} ();
  \path[->] (6) edge[loop right] node {0.5} ();

  \path[->] (1) edge[bend left] node {0.9} (2);
  \path[->] (2) edge[bend left] node {0.4} (1);
  \path[->] (2) edge[bend left] node {0.4} (3);
  \path[->] (3) edge[bend left] node {0.5} (2);
  \path[->] (3) edge[bend left] node {0.5} (4);
  \path[->] (4) edge[bend left] node {0.5} (3);
  \path[->] (5) edge[bend left] node {0.7} (6);
  \path[->] (6) edge[bend left] node {0.5} (5);

  \path[->] (4) edge[dashed, bend left] node {$\epsilon$} (5);
  \path[->] (5) edge[dashed, bend left] node {$\epsilon$} (4);
\end{tikzpicture}
```

This means that typically, $(X_n)$ will spend a long time in $\{1, 2, 3, 4\}$, with faster-than usual return times, until finally moving to $\{5,6\}$, with no visits to $1,2,3$ or $4$ and a very long return time.

Of course, the results of the course on long-run proportion of time and expected return times are still true. But convergence will be very slow, and it will typically take an extremely long time for this behaviour to average out -- perhaps $N$ equal to a million for $\epsilon = 0.01$ or more than a billion for $\epsilon = 10^{-6}$ might be necessary.

For $\epsilon = 0$, the Markov chain splits into two different losed communicating classes, and the Markov chain will stay in $\{1,2,3,4\}$ (if it starts from $X_0 = 1$) forever. The results that required an irreducible Markov chain no longer hold true. We will need to study the two communicating classes separately.



***



### Note on this report


This example report was written using **[R Markdown](https://rmarkdown.rstudio.com/lesson-1.html)**, which allows the easy integration of text, LaTeX, displayed R code, and executed R code in one document. Upsides of using R Markdown include that it's a convenient way to turn some R code into a documented report, and that the output looks professional. Downsides include that it's another thing to learn, and that it rarely works properly on University computers. If you'd like to try, I recommend reading [Using R Markdown for Class Reports ](https://www.stat.cmu.edu/~cshalizi/rmarkdown/) by Cosma Shalizi.

You can download the [R Markdown source code for this report here](https://mpaldridge.github.io/math2750/C2-example.Rmd). If you open that file in RStudio and click on `knit`, it should produce [the HTML version of the report](https://mpaldridge.github.io/math2750/C2-example.html) --  although it probably won't work on a University computer. Note also that the R code (including generation of random numbers) is run anew, so your graphs and sample estimates will not be exactly the same as mine.

